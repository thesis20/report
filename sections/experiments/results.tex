\subsection{Results of experiments}\label{subsec:resultsofexperiment}
In this section we look at the results from the experiments.
\subsubsection{LDOS-CoMoDa}
For the experiments conducted on the LDOS-CoMoDa dataset, we should see the methods that handle context do well, as this dataset has many context variables that the rating depends on.
As mentioned, we are looking at two of these context variables, which are the \textit{dominantEmo} and the \textit{physical} attributes as these are some of the most influential, as described in \autoref{subsec:desc-of-datasets}.
The methods that handle context are \texttt{Itemsplitting} and the \texttt{CAMF} methods.
We see that \texttt{Itemsplitting} has the largest Recall@10, but also the smallest Precision@10, resulting in a small F1@10 value, and in general, it does not perform well on LDOS-CoMoDa, which is surprising as it is able to utilize the context.
However, \texttt{Itemsplitting} is able to achieve one of the highest NDCG scores.
Both \texttt{CAMF-C} and \texttt{CAMF-CI} perform well on LDOS-CoMoDA in terms of most metrics, except for MAP@N.
They are able to achieve the lowest prediction errors amongst all methods in terms of RMSE and MAE, which could indicate that they are able to make good use of the context.
Close to \texttt{CAMF} methods we have baselines such as \texttt{SVD} and \texttt{SVD++} which both are competitive in terms of precision@10, Recall@10 and F1@10. 
These also achieve the highest MAP@N values but do not have as low prediction errors as the \texttt{CAMF} methods.
\texttt{NMF} generally perform a little worse in all metrics compared to \texttt{SVD}, except for NDCG.
The \texttt{DeepWalk + kNN} method has high prediction errors and low Precision@10 and MAP@10 values but has the second-highest Recall@10 and one of the highest NDCG value.
Finally, we have the methods that do not handle rating predictions but only do top-$N$ recommendations, so these do not have RMSE and MAE values, since they work with interactions rather than ratings.
We see that \texttt{LightGCN} is not able to perform well on any of the metrics.
We suspect that this is because the LDOS-CoMoDa dataset is as small as it is with only 121 users, 1,232 unique movies, and 2,296 ratings, and it is therefore not able to utilize its strengths.
And all of these numbers are considerably lower on the actual data used, due to pruning.
However, \texttt{NGCF} is able to achieve both the highest Precision@10 as well as the highest NDCG but does have a lower Recall@10 resulting in a low F1@10 score.
\\\\
To summarize, we expected the context-aware methods to perform well on the LDOS-CoMoDA dataset, as the ratings are context-dependent. 
The \texttt{CAMF} methods do perform well as expected, but \texttt{Itemsplitting} is underperforming in most metrics.
Some baselines such as \texttt{SVD} and \texttt{SVD++} are closely competitive with \texttt{CAMF} as the best performing methods.
The results of the experiment could also indicate that \texttt{NGCF} could be interesting to look at in terms of adding context, as it is able to perform well on a context dataset without utilizing the context available. 
\texttt{NGCF} is also a graph-based approach which, as mentioned in \autoref{sec:graph-rec-sys}, is able to alleviate the sparsity problem introduced by adding context.
