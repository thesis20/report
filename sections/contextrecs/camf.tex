\subsection{Context-Aware Matrix Factorization}
One of the context-aware recommender system methods we have looked into is context-aware matrix factorization (CAMF)\cite{baltrunasCAMF}.
As no implementation was available for the method, all results are based on our implementation.
The method is an extension of the classical Matrix Factorization (MF) approach which takes the contextual side information into account when making rating predictions.
There are different models of CAMF that deal with different levels of granularity in terms of the context.
For CAMF-C, it is assumed that each of the contextual conditions has a global influence on the ratings independently of the items.
In the CAMF-C model, a single parameter is introduced for each value of each contextual factor.
The second model is CAMF-CI which introduces a parameter for each contextual condition and item pair, meaning that it has a finer granularity.
By modeling it like this, it is possible to capture when the contextual factors have a different effect on the rating depending on which item it is.
The expression for predicting ratings with the CAMF models is seen in \autoref{eqn:camf-rating-pred}.
\begin{equation}
    \label{eqn:camf-rating-pred}
    \hat{r}_{uic_1...c_k} = \vec{v_u} * \vec{q_i} + \bar{i} + b_u + \sum\limits_{j = 1}^k B_{ijc_j}
\end{equation}
We have that $\hat{r}_{uic_1...c_k}$ is the predicted rating for user $u$, item $i$ under the contextual values $c_1...c_k$.
The variables $\vec{v_u} $ and $ \vec{q_i}$ are the feature vectors for user $u$ and item $i$ which are multiplied, just as in matrix factorization.
$\bar{i}$ is the global average rating for item $i$, meaning the average rating across all users in the training set, and $\bar{b_u}$ is a user bias.
$B_{ijc_j}$ are the parameters modeling the interaction of the contextual conditions and the items.
For the CAMF-CI model, $B_{ijc_j}$ will result in a lot of parameters, and for CAMF-C it will result in less, as a result of how the two different approaches perform the contextual modeling.
All of the parameters in the model, except for the average item rating, are learned through stochastic gradient descent.
This is done through the use of a loss function which is seen in \autoref{eqn:camf-loss-func}.
\begin{equation}
    \label{eqn:camf-loss-func}
    \begin{split}
        \min_{v*, q*, b*, B*}\sum \limits_{r \in  R}\left [ \left (  \hat{r}_{uic_1...c_k} - \vec{v_u} * \vec{q_i} - \bar{i} - b_u - \sum\limits_{j = 1}^k B_{ijc_j}\right )^2 \right. \\
        \left. + \lambda \left({b_u}^2 +{\left \| \vec{v_u} \right \|}^2  + {\left \|\vec{q_i}  \right \|}^2 + \sum\limits_{j = 1}^k \sum\limits_{c_j = 1}^{z_j} B_{ijc_j}^{2}\right ) \right ]
    \end{split}
\end{equation}
Here we have that $r = (u,i,c_1...c_k)$ and that R is the context-dependent ratings from the training set.
The loss function includes regularization controlled by the $\lambda$ parameter to avoid overfitting the training data.
The parameters are then updated based on the gradient of the loss function for each of the ratings in the training set.
